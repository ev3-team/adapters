import { AdapterProject } from '../types'

export default {
  name: 'vLLM',
  ninja: '0x7Ef3169903033C30FF3Da674BD793B236F21B026',
  subcategories: 'Inference',
  chain: null,
  category: 'AI',
  token: null,
  coinGeckoID: null,
  id: 'x2t025',
  description:
    'vLLM is an open-source, high-throughput, and memory-efficient inference and serving engine for LLMs, designed to optimize performance and reduce costs for AI deployments.',
  discord: null,
  investors: [],
  linkedin: null,
  duneQueries: null,
  foundingYear: null,
  blog: null,
  github: null,
  telegram: null,
  twitter: 'https://x.com/vllm_project',
  url: null,
  verified: false,
  fundraises: [],
  isApp: true,
} satisfies AdapterProject
